#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –º–∏–≥—Ä–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ñ–∞–π–ª–æ–≤ –≤ PostgreSQL –ë–î –¥–ª—è —Å–∏—Å—Ç–µ–º—ã Lexus

–ß–∏—Ç–∞–µ—Ç:
- targets.txt - —Å–ø–∏—Å–æ–∫ –≥—Ä—É–ø–ø
- group_niches.json - –º–∞–ø–ø–∏–Ω–≥ –≥—Ä—É–ø–ø –Ω–∞ –Ω–∏—à–∏
- group_account_assignments.json - –ø—Ä–∏–≤—è–∑–∫–∞ –≥—Ä—É–ø–ø –∫ –∞–∫–∫–∞—É–Ω—Ç–∞–º (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
- accounts_config.json - —Å–ø–∏—Å–æ–∫ –∞–∫–∫–∞—É–Ω—Ç–æ–≤ (–¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∑–∞–ø–∏—Å–µ–π –≤ accounts)

–ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç –≤ –ë–î:
- accounts - –∏–∑ accounts_config.json (—Ç–æ–ª—å–∫–æ Lexus –∞–∫–∫–∞—É–Ω—Ç—ã)
- targets - –∏–∑ targets.txt –∏ group_niches.json
- –ü—Ä–∏–≤—è–∑–∫–∏ –≥—Ä—É–ø–ø –∫ –∞–∫–∫–∞—É–Ω—Ç–∞–º - –∏–∑ group_account_assignments.json (–µ—Å–ª–∏ –µ—Å—Ç—å)
"""
import asyncio
import json
import sys
import logging
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, Optional, Set

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–µ–Ω—å –ø—Ä–æ–µ–∫—Ç–∞ –≤ –ø—É—Ç—å
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from lexus_db.session import AsyncSessionLocal, init_db, get_database_url
from lexus_db.models import Account, Target
from lexus_db.db_manager import DbManager

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def load_accounts_config(config_file: str = 'accounts_config.json') -> list:
    """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∞–∫–∫–∞—É–Ω—Ç–æ–≤"""
    try:
        with open(config_file, 'r', encoding='utf-8') as f:
            accounts = json.load(f)
        logger.info(f"‚úÖ Loaded {len(accounts)} accounts from {config_file}")
        return accounts
    except FileNotFoundError:
        logger.error(f"‚ùå Config file {config_file} not found")
        return []
    except json.JSONDecodeError as e:
        logger.error(f"‚ùå Invalid JSON in {config_file}: {e}")
        return []


def load_lexus_accounts_config(config_file: str = 'lexus_accounts_config.json') -> Set[str]:
    """–ó–∞–≥—Ä—É–∑–∫–∞ —Å–ø–∏—Å–∫–∞ —Ä–∞–∑—Ä–µ—à–µ–Ω–Ω—ã—Ö –∞–∫–∫–∞—É–Ω—Ç–æ–≤ –¥–ª—è Lexus"""
    try:
        with open(config_file, 'r', encoding='utf-8') as f:
            config = json.load(f)
        allowed_accounts = set(config.get('allowed_accounts', []))
        logger.info(f"‚úÖ Loaded {len(allowed_accounts)} Lexus accounts from {config_file}")
        return allowed_accounts
    except FileNotFoundError:
        logger.warning(f"‚ö†Ô∏è Config file {config_file} not found, using all accounts")
        return set()
    except json.JSONDecodeError as e:
        logger.warning(f"‚ö†Ô∏è Invalid JSON in {config_file}: {e}, using all accounts")
        return set()


def load_targets(file_path: str = 'targets.txt') -> list:
    """–ó–∞–≥—Ä—É–∑–∫–∞ —Å–ø–∏—Å–∫–∞ –≥—Ä—É–ø–ø –∏–∑ targets.txt"""
    try:
        targets = []
        with open(file_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#'):
                    targets.append(line)
        logger.info(f"‚úÖ Loaded {len(targets)} targets from {file_path}")
        return targets
    except FileNotFoundError:
        logger.warning(f"‚ö†Ô∏è File {file_path} not found")
        return []


def load_group_niches(file_path: str = 'group_niches.json') -> Dict[str, str]:
    """–ó–∞–≥—Ä—É–∑–∫–∞ –º–∞–ø–ø–∏–Ω–≥–∞ –≥—Ä—É–ø–ø –Ω–∞ –Ω–∏—à–∏"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            niches = json.load(f)
        logger.info(f"‚úÖ Loaded {len(niches)} group-niche mappings from {file_path}")
        return niches
    except FileNotFoundError:
        logger.warning(f"‚ö†Ô∏è File {file_path} not found")
        return {}
    except json.JSONDecodeError as e:
        logger.error(f"‚ùå Invalid JSON in {file_path}: {e}")
        return {}


def load_group_assignments(file_path: str = 'group_account_assignments.json') -> Dict[str, Dict]:
    """–ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–∏–≤—è–∑–∫–∏ –≥—Ä—É–ø–ø –∫ –∞–∫–∫–∞—É–Ω—Ç–∞–º"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            assignments = json.load(f)
        logger.info(f"‚úÖ Loaded {len(assignments)} group-account assignments from {file_path}")
        return assignments
    except FileNotFoundError:
        logger.info(f"‚ÑπÔ∏è File {file_path} not found, skipping assignments")
        return {}
    except json.JSONDecodeError as e:
        logger.warning(f"‚ö†Ô∏è Invalid JSON in {file_path}: {e}, skipping assignments")
        return {}


def normalize_group_link(link: str) -> str:
    """–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Å—Å—ã–ª–∫–∏ –Ω–∞ –≥—Ä—É–ø–ø—É"""
    link = link.strip()
    
    if link.startswith('https://'):
        link = link[8:]
    elif link.startswith('http://'):
        link = link[7:]
    
    if link.startswith('t.me/'):
        link = link[5:]
    elif link.startswith('telegram.me/'):
        link = link[12:]
    
    if not link.startswith('@'):
        link = '@' + link
    
    return link


async def migrate_accounts(session, accounts_config: list, lexus_allowed: Set[str]) -> Dict[str, int]:
    """
    –ú–∏–≥—Ä–∞—Ü–∏—è –∞–∫–∫–∞—É–Ω—Ç–æ–≤ –≤ –ë–î
    
    Returns:
        –°–ª–æ–≤–∞—Ä—å {session_name: account_id}
    """
    logger.info("=" * 80)
    logger.info("üì• MIGRATING ACCOUNTS")
    logger.info("=" * 80)
    
    account_id_map = {}
    created_count = 0
    updated_count = 0
    
    # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ Lexus –∞–∫–∫–∞—É–Ω—Ç—ã
    lexus_accounts = [
        acc for acc in accounts_config
        if acc.get('session_name') in lexus_allowed
    ]
    
    if not lexus_allowed:
        logger.warning("‚ö†Ô∏è No Lexus accounts whitelist, migrating ALL accounts")
        lexus_accounts = accounts_config
    
    logger.info(f"üìã Migrating {len(lexus_accounts)} Lexus accounts")
    
    for acc_config in lexus_accounts:
        session_name = acc_config.get('session_name')
        if not session_name:
            logger.warning(f"‚ö†Ô∏è Account without session_name, skipping: {acc_config}")
            continue
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ –∞–∫–∫–∞—É–Ω—Ç
        from sqlalchemy import select
        stmt = select(Account).where(Account.session_name == session_name)
        result = await session.execute(stmt)
        existing_account = result.scalar_one_or_none()
        
        if existing_account:
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π
            existing_account.phone = acc_config.get('phone')
            existing_account.session_string = acc_config.get('string_session')
            existing_account.updated_at = datetime.utcnow()
            account_id_map[session_name] = existing_account.id
            updated_count += 1
            logger.debug(f"  üîÑ Updated account: {session_name}")
        else:
            # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π
            new_account = Account(
                session_name=session_name,
                phone=acc_config.get('phone'),
                session_string=acc_config.get('string_session'),
                status='active',
                daily_posts_count=0,
                last_stats_reset=datetime.utcnow()
            )
            session.add(new_account)
            await session.flush()  # –ß—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å ID
            account_id_map[session_name] = new_account.id
            created_count += 1
            logger.debug(f"  ‚úÖ Created account: {session_name} (id={new_account.id})")
    
    await session.commit()
    logger.info(f"‚úÖ Accounts migration complete: {created_count} created, {updated_count} updated")
    logger.info(f"   Total accounts in map: {len(account_id_map)}")
    
    return account_id_map


async def migrate_targets(
    session,
    targets_list: list,
    group_niches: Dict[str, str],
    account_id_map: Dict[str, int],
    assignments: Dict[str, Dict]
) -> int:
    """
    –ú–∏–≥—Ä–∞—Ü–∏—è –≥—Ä—É–ø–ø –≤ –ë–î
    
    Returns:
        –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–∑–¥–∞–Ω–Ω—ã—Ö/–æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã—Ö –≥—Ä—É–ø–ø
    """
    logger.info("=" * 80)
    logger.info("üì• MIGRATING TARGETS (GROUPS)")
    logger.info("=" * 80)
    
    created_count = 0
    updated_count = 0
    assigned_count = 0
    
    from sqlalchemy import select
    
    for target_link in targets_list:
        normalized_link = normalize_group_link(target_link)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–∏—à—É
        niche = group_niches.get(target_link, group_niches.get(normalized_link, 'ukraine_cars'))
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ –≥—Ä—É–ø–ø–∞
        stmt = select(Target).where(Target.link == normalized_link)
        result = await session.execute(stmt)
        existing_target = result.scalar_one_or_none()
        
        if existing_target:
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é
            if existing_target.niche != niche:
                existing_target.niche = niche
            existing_target.updated_at = datetime.utcnow()
            updated_count += 1
            target = existing_target
        else:
            # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é
            target = Target(
                link=normalized_link,
                niche=niche,
                status='new',  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é 'new', –±—É–¥–µ—Ç 'joined' –ø–æ—Å–ª–µ –≤—Å—Ç—É–ø–ª–µ–Ω–∏—è
                daily_posts_in_group=0,
                last_group_stats_reset=datetime.utcnow()
            )
            session.add(target)
            await session.flush()  # –ß—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å ID
            created_count += 1
        
        # –ü—Ä–∏–≤—è–∑—ã–≤–∞–µ–º –∫ –∞–∫–∫–∞—É–Ω—Ç—É, –µ—Å–ª–∏ –µ—Å—Ç—å assignment
        assignment = assignments.get(target_link) or assignments.get(normalized_link)
        if assignment:
            assigned_account_name = assignment.get('account_name') or assignment.get('account')
            if assigned_account_name and assigned_account_name in account_id_map:
                account_id = account_id_map[assigned_account_name]
                
                # –ü–∞—Ä—Å–∏–º joined_at –∏–∑ assignment
                joined_at_str = assignment.get('joined_at') or assignment.get('joined_at_iso')
                if joined_at_str:
                    try:
                        joined_at = datetime.fromisoformat(joined_at_str.replace('Z', '+00:00'))
                    except:
                        joined_at = datetime.utcnow() - timedelta(hours=24)  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –º–∏–Ω—É—Å 24 —á–∞—Å–∞
                else:
                    # –ï—Å–ª–∏ –Ω–µ—Ç –¥–∞—Ç—ã –≤—Å—Ç—É–ø–ª–µ–Ω–∏—è, —Å—á–∏—Ç–∞–µ–º —á—Ç–æ –≤—Å—Ç—É–ø–∏–ª–∏ 24 —á–∞—Å–∞ –Ω–∞–∑–∞–¥ (warm-up —É–∂–µ –ø—Ä–æ—à–µ–ª)
                    joined_at = datetime.utcnow() - timedelta(hours=24)
                
                # –ü—Ä–∏–≤—è–∑—ã–≤–∞–µ–º
                target.assigned_account_id = account_id
                target.status = 'joined'
                target.set_warmup_ends_at(joined_at)
                assigned_count += 1
                logger.debug(
                    f"  üîó Assigned {normalized_link} to {assigned_account_name} "
                    f"(joined_at={joined_at}, warmup_ends_at={target.warmup_ends_at})"
                )
    
    await session.commit()
    logger.info(f"‚úÖ Targets migration complete:")
    logger.info(f"   Created: {created_count}")
    logger.info(f"   Updated: {updated_count}")
    logger.info(f"   Assigned to accounts: {assigned_count}")
    
    return created_count + updated_count


async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –º–∏–≥—Ä–∞—Ü–∏–∏"""
    logger.info("=" * 80)
    logger.info("üöÄ LEXUS DATABASE MIGRATION FROM FILES")
    logger.info("=" * 80)
    logger.info(f"Database URL: {get_database_url().replace(get_database_url().split('@')[0].split('//')[1], '***')}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ñ–∞–π–ª–æ–≤
    base_dir = Path('.')
    targets_file = base_dir / 'targets.txt'
    niches_file = base_dir / 'group_niches.json'
    accounts_file = base_dir / 'accounts_config.json'
    lexus_config_file = base_dir / 'lexus_accounts_config.json'
    assignments_file = base_dir / 'group_account_assignments.json'
    
    if not targets_file.exists():
        logger.error(f"‚ùå {targets_file} not found!")
        return
    
    if not niches_file.exists():
        logger.error(f"‚ùå {niches_file} not found!")
        return
    
    if not accounts_file.exists():
        logger.error(f"‚ùå {accounts_file} not found!")
        return
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ñ–∞–π–ª–æ–≤
    logger.info("\nüìÇ Loading data from files...")
    targets_list = load_targets(str(targets_file))
    group_niches = load_group_niches(str(niches_file))
    accounts_config = load_accounts_config(str(accounts_file))
    lexus_allowed = load_lexus_accounts_config(str(lexus_config_file))
    assignments = load_group_assignments(str(assignments_file))
    
    if not targets_list:
        logger.error("‚ùå No targets to migrate!")
        return
    
    if not accounts_config:
        logger.error("‚ùå No accounts to migrate!")
        return
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ë–î
    logger.info("\nüóÑÔ∏è Initializing database...")
    try:
        await init_db()
        logger.info("‚úÖ Database initialized")
    except Exception as e:
        logger.error(f"‚ùå Failed to initialize database: {e}", exc_info=True)
        return
    
    # –í—ã–ø–æ–ª–Ω—è–µ–º –º–∏–≥—Ä–∞—Ü–∏—é
    async with AsyncSessionLocal() as session:
        try:
            # –ú–∏–≥—Ä–∏—Ä—É–µ–º –∞–∫–∫–∞—É–Ω—Ç—ã
            account_id_map = await migrate_accounts(session, accounts_config, lexus_allowed)
            
            if not account_id_map:
                logger.error("‚ùå No accounts migrated, cannot continue!")
                return
            
            # –ú–∏–≥—Ä–∏—Ä—É–µ–º –≥—Ä—É–ø–ø—ã
            await migrate_targets(session, targets_list, group_niches, account_id_map, assignments)
            
            logger.info("=" * 80)
            logger.info("‚úÖ MIGRATION COMPLETE!")
            logger.info("=" * 80)
            
        except Exception as e:
            await session.rollback()
            logger.error(f"‚ùå Migration failed: {e}", exc_info=True)
            raise


if __name__ == "__main__":
    asyncio.run(main())
