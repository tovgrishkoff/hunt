#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —É–∫—Ä–∞–∏–Ω—Å–∫–∏—Ö –∞–≤—Ç–æ-–≥—Ä—É–ø–ø –≤ targets.txt –∏ group_niches.json
–ó–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–≥–æ –≤—Å—Ç—É–ø–ª–µ–Ω–∏—è –≤ –≥—Ä—É–ø–ø—ã
"""

import json
import logging
import sys
from pathlib import Path
from datetime import datetime

def setup_logging():
    """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è"""
    log_dir = Path('logs')
    log_dir.mkdir(exist_ok=True)
    
    log_file = log_dir / 'add_ukraine_cars_to_targets.log'
    
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_file, encoding='utf-8'),
            logging.StreamHandler()
        ]
    )
    
    return logging.getLogger(__name__)

def add_groups_to_targets():
    """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –≥—Ä—É–ø–ø –≤ targets.txt –∏ group_niches.json"""
    logger = setup_logging()
    
    logger.info("=" * 80)
    logger.info("üìù –î–û–ë–ê–í–õ–ï–ù–ò–ï –£–ö–†–ê–ò–ù–°–ö–ò–• –ê–í–¢–û-–ì–†–£–ü–ü –í –†–ê–°–°–´–õ–ö–£")
    logger.info("=" * 80)
    
    found_file = Path('logs/found_ukraine_cars_groups.json')
    targets_file = Path('targets.txt')
    niches_file = Path('group_niches.json')
    
    if not found_file.exists():
        logger.warning(f"‚ö†Ô∏è –§–∞–π–ª {found_file} –Ω–µ –Ω–∞–π–¥–µ–Ω! –ì—Ä—É–ø–ø—ã –µ—â–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.")
        return
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –≥—Ä—É–ø–ø—ã
    try:
        with found_file.open('r', encoding='utf-8') as f:
            found_groups = json.load(f)
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ {found_file}: {e}")
        return
    
    if not found_groups:
        logger.info("‚ÑπÔ∏è –ù–µ—Ç –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –≥—Ä—É–ø–ø –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è")
        return
    
    logger.info(f"üìã –ù–∞–π–¥–µ–Ω–æ –≥—Ä—É–ø–ø –≤ —Ñ–∞–π–ª–µ: {len(found_groups)}")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ targets
    existing_targets = set()
    if targets_file.exists():
        try:
            with targets_file.open('r', encoding='utf-8') as f:
                existing_targets = {line.strip() for line in f if line.strip() and not line.strip().startswith('#')}
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ {targets_file}: {e}")
    
    logger.info(f"üìã –£–∂–µ –≤ targets.txt: {len(existing_targets)} –≥—Ä—É–ø–ø")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –Ω–∏—à–∏
    existing_niches = {}
    if niches_file.exists():
        try:
            with niches_file.open('r', encoding='utf-8') as f:
                existing_niches = json.load(f)
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ {niches_file}: {e}")
    
    # –°–æ–∑–¥–∞–µ–º backup
    if targets_file.exists():
        backup_file = Path(f'targets.txt.backup_{datetime.now().strftime("%Y%m%d_%H%M%S")}')
        try:
            import shutil
            shutil.copy2(targets_file, backup_file)
            logger.info(f"üíæ –°–æ–∑–¥–∞–Ω backup: {backup_file}")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å backup: {e}")
    
    if niches_file.exists():
        backup_file = Path(f'group_niches.json.backup_{datetime.now().strftime("%Y%m%d_%H%M%S")}')
        try:
            import shutil
            shutil.copy2(niches_file, backup_file)
            logger.info(f"üíæ –°–æ–∑–¥–∞–Ω backup: {backup_file}")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å backup: {e}")
    
    # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ –≥—Ä—É–ø–ø—ã
    added_count = 0
    updated_niches = {}
    
    for group in found_groups:
        username = group.get('username', '')
        if not username:
            continue
        
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º, –µ—Å–ª–∏ —É–∂–µ –µ—Å—Ç—å –≤ targets.txt
        if username in existing_targets:
            # –ù–æ –æ–±–Ω–æ–≤–ª—è–µ–º –Ω–∏—à—É, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if username not in existing_niches or existing_niches.get(username) != 'ukraine_cars':
                updated_niches[username] = 'ukraine_cars'
            continue
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤ targets.txt
        try:
            with targets_file.open('a', encoding='utf-8') as f:
                f.write(f"{username}\n")
            existing_targets.add(username)
            added_count += 1
            logger.info(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–∞ –≥—Ä—É–ø–ø–∞: {username} (–Ω–∏—à–∞: ukraine_cars)")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ {username} –≤ targets.txt: {e}")
            continue
        
        # –î–æ–±–∞–≤–ª—è–µ–º –Ω–∏—à—É
        updated_niches[username] = 'ukraine_cars'
    
    # –û–±–Ω–æ–≤–ª—è–µ–º group_niches.json
    existing_niches.update(updated_niches)
    try:
        with niches_file.open('w', encoding='utf-8') as f:
            json.dump(existing_niches, f, ensure_ascii=False, indent=2)
        logger.info(f"‚úÖ –û–±–Ω–æ–≤–ª–µ–Ω group_niches.json: –¥–æ–±–∞–≤–ª–µ–Ω–æ/–æ–±–Ω–æ–≤–ª–µ–Ω–æ {len(updated_niches)} –≥—Ä—É–ø–ø —Å –Ω–∏—à–µ–π 'ukraine_cars'")
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ group_niches.json: {e}")
    
    logger.info("")
    logger.info("=" * 80)
    logger.info(f"‚úÖ –ó–ê–í–ï–†–®–ï–ù–û:")
    logger.info(f"   - –î–æ–±–∞–≤–ª–µ–Ω–æ –Ω–æ–≤—ã—Ö –≥—Ä—É–ø–ø –≤ targets.txt: {added_count}")
    logger.info(f"   - –û–±–Ω–æ–≤–ª–µ–Ω–æ –Ω–∏—à –≤ group_niches.json: {len(updated_niches)}")
    logger.info("=" * 80)
    
    return added_count, len(updated_niches)

if __name__ == "__main__":
    add_groups_to_targets()


